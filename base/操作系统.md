# 操作系统
## 一. 概述
### 2.1 操作系统基本功能

1. **进程管理**：进程控制、进程同步、进程通信、死锁处理、处理机调度等。
2. **内存管理**：内存分配、地址映射、内存保护与共享、内存扩充等。
3. **文件管理**：文件存储空间的管理、目录管理、文件读写管理和保护等。
4. **设备管理**：完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

## 二. 进程管理
**进程**是**资源分配**的基本单位。**线程**是**独立调度**的基本单位。

### 2.1 线程
#### 2.1.2 好处
 - 易于调度。
 - 提高并发性。通过线程可方便有效地实现并发性。进程可创建多个线程来执行同一程序的不同部分。
 - 开销少。创建线程比创建进程要快，所需开销很少。
 - 利于充分发挥多处理器的功能。通过创建多线程进程，每个线程在一个处理器上运行，从而实现应用程序的并发性，使每个处理器都得到充分运行。

#### 2.1.3 线程状态
联系java中线程的几种状态 java thread的运行周期中, 有几种状态, 在 java.lang.Thread.State 中有详细定义和说明:

- **NEW**:状态是指线程刚创建, 尚未启动
- **RUNNABLE**: 状态是线程正在正常运行中,当然可能会有某种耗时计算/IO等待的操作/CPU时间片切换等,这个状态下发生的等待一般是其他系统资源, 而不是锁, Sleep等.
- **BLOCKED** 这个状态下, 是在多个线程有同步操作的场景,比如正在等待另一个线程的synchronized 块的执行释放, 或者可重入的 synchronized块里别人调用wait() 方法,也就是这里是线程在等待进入临界区
- **WAITING**这个状态下是指线程拥有了某个锁之后, 调用了他的wait方法, 等待其他线程/锁拥有者调用 notify / notifyAll 一遍该线程可以继续下一步操作, 这里要区分 BLOCKED 和 WATING 的区别, 一个是在临界点外面等待进入, 一个是在理解点里面wait等待别人notify, 线程调用了join方法 join了另外的线程的时候, 也会进入WAITING状态, 等待被他join的线程执行结束
- **TIMED_WAITING**这个状态就是有限的(时间限制)的WAITING, 一般出现在调用wait(long), join(long)等情况下, 另外一个线程sleep后, 也会进入TIMED_WAITING状态
- **TERMINATED**这个状态下表示该线程的run方法已经执行完毕了,基本上就等于死亡了(当时如果线程被持久持有, 可能不会被回收)

### 2.2 进程
#### 进程的几种状态
 - **创建状态(New)**：进程正在创建过程中，还不能运行。操作系统在创建状态要进行的工作包括分配和建立进程控制块表项、建立资源表格(如打开文件表)并分配资源、加载程序并建立地址空间表等。
 - **就绪状态(Ready)**：进程已获得除处理器外的所需资源，等待分配处理器资源；只要分配了处理器进程就可执行。就绪进程可以按多个优先级来划分队列。例如，当一个进程由于时间片用完而进入就绪状态时，排人低优先级队列；当进程由I／O操作完成而进入就绪状态时，排入高优先级队列。
 - **执行状态**: 进程已获得CPU，其程序正在执行。在单处理机系统中，只有一个进程处于执行状态； 在多处理机系统中，则有多个进程处于执行状态。
 - **阻塞状态**:正在执行的进程由于发生某事件而暂时无法继续执行时，便放弃处理机而处于暂停状态，亦即进程的执行受到阻塞，把这种暂停状态称为阻塞状态，有时也称为等待状态或封锁状态。致使进程阻塞的典型事件有：请求I/O，申请缓冲空间等。通常将这种处于阻塞状态的进程也排成一个队列。有的系统则根据阻塞原因的不同而把处于阻塞状态的进程排成多个队列。
 - **退出状态(Exit)**：进程已结束运行，回收除进程控制块之外的其他资源，并让其他进程从进程控制块中收集有关信息(如记帐和将退出代码传递给父进程)。

#### 作业(进程)调度算法

1. **先来先服务调度算法(FCFS)** 每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。
2. **短作业(进程)优先调度算法(SPF)**：短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。缺点:长作业的运行得不到保证
3. **优先权调度算法(HPF)**：当把该算法用于作业调度时，系统将从后备队列中选择若干个**优先权最高**的作业装入内存。
4. **高响应比优先调度算法(HRN)**:每次选择高响应比最大的作业执行，响应比=(等待时间+要求服务时间)/要求服务时间。该算法同时考虑了短作业优先和先来先服务。
5. **时间片轮转法（RR）**:系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU分配给队首进程，并令其执行一个时间片。当执行的时间片用完时, 将它送往就绪队列的末尾, 然后，再把处理机分配给就绪队列中新的队首进程.
6. **多级反馈队列调度算法** 它是目前被公认的一种较好的进程调度算法。

  - 应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第i+1个队列的时间片要比第i个队列的时间片长一倍。

  - 当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第n队列后，在第n 队列便采取按时间片轮转的方式运行。

 - 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i队列的末尾，把处理机分配给新到的高优先权进程。

### 进程和线程的关系

 - 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。
 - 资源分配给进程，同一进程的所有线程共享该进程的所有资源。
 - 处理机分给线程，即真正在处理机上运行的是线程。
 - 线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。线程是指进程内的一个执行单元,也是进程内的可调度实体.

### 进程与线程区别

 - **拥有资源**：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

 - **调度**：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。

 - **系统开销**：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

 - **通信方面**：进程间通信 (IPC) 需要进程同步和互斥手段的辅助，以保证数据的一致性。而线程间可以通过直接读/写同一进程中的数据段（如全局变量）来进行通信。

### IPC几种通信方式(进程间的通信方式)
#### 管道( pipe )
管道是单向的、先进先出的、无结构的、固定大小的字节流，它把一个进程的标准输出和另一个进程的标准输入连接在一起。写进程在管道的尾端写入数据，读进程在管道的首端读出数据。数据读出后将从管道中移走，其它读进程都不能再读到这些数据。

管道有三种：

 - **普通管道**：有两个限制：一是只支持半双工通信方式，即只能单向传输；二是只能在父子进程之间使用；
 - **流管道**：去除第一个限制，支持双向传输；
 - **命名管道**：去除第二个限制，可以在不相关进程之间进行通信。

#### 信号 ( sinal )
信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。除了用于进程通信外，进程还可以发送信号给进程本身。

#### 信号量( semophore )
信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

#### 共享内存( shared memory )：
共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的IPC方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量配合使用，来实现进程间的同步和通信。

#### 消息队列( message queue )： 
消息队列是由消息的链表结构实现，存放在内核中并由消息队列标识符标识。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。


#### 套接字( socket )： 
也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。

### 2.3.死锁的必要条件，怎么处理死锁。
#### 2.3.1 死锁概念
 是指两个或两个以上的进程在执行过程中，**由于竞争资源或者由于彼此通信而造成的一种阻塞的现象**，若无外力作用，它们都将无法推进下去。
### 2.3.2 活锁
活锁指的是任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。

### 2.3.3 死锁条件

1. **互斥条件**:一个资源每次只能被一个进程使用
2. **不可剥夺条件**:进程已获得的资源，在末使用完之前，不能强行剥夺
3. **请求与保持条件**:一个进程因请求资源而阻塞时，对已获得的资源保持不放
4. **循环等待条件**:若干进程之间形成一种头尾相接的循环等待资源关系.

### 2.3.4 死锁预防
1. **破坏互斥条件**。允许某些进程(线程)同时访问某些资源，但有的资源不允许同时被访问如打印机等。例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

2. **破坏不可抢占条件**:即允许进程强行从占有者那里夺取某些资源。这种预防方法实现起来困难，会降低系统性能。

3. **破坏占有且申请条件**。可以实行预先分配策略，即进程在运行前一次性地向系统申请它所需要的全部资源。如果当前进程所需的全部资源得不到满足，则不分配任何资源。只有当系统能够满足当前的全部资源得到满足时，才一次性将所有申请的资源全部分配给该进程。由于运行的进程已占有了它所需的全部资源，所以不会发生占有资源又重新申请资源的现象，因此不会发生死锁。但是有以下缺点：

  - 在许多情况下，一个进程在执行之前不可能知道它所需的全部资源。这是由于进程在执行时是动态的，不可预测的。

  - 资源利用率低。无论所分配资源何时用到，一个进程只有在占有所需的全部资源后才能执行。即使有些资源最后才被该进程用到一次，但该进程在生存期间一直占有它们，造成长期占有。

  - 降低了进程的并发性。因为资源有限，又加上存在浪费，能分配到所需全部资源的进程个数必然少了。

4. **破坏循环等待条件**。实行资源有序分配策略。采用这种策略即把资源事先分类编号，按号分配。所有进程对资源的请求必须严格按资源需要递增的顺序提出。进程占用小好资源，才能申请大号资源，就不会产生环路。这种策略与前面的策略相比，资源的利用率和系统吞吐量都有很大提高，但是也存在以下缺点：

  - 限制了进程对资源的请求，同时系统给所有资源合理编号也是件困难事，并增加了系统开销。

### 2.3.4 死锁的避免
1. **银行家算法**：该算法需要检查申请者对资源的最大需求量，如果系统现存的各类资源可以满足申请者的请求，就满足申请者的请求。这样申请者就可很快完成其计算，然后释放它占用的资源，从而保证了系统中的所有进程都能完成，所以可避免死锁的发生。


### 2.3.5 死锁的解除
一旦检测出死锁，就应立即釆取相应的措施，以解除死锁。
死锁解除的主要方法有：

 - **资源剥夺法**。挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源，而处于资源匮乏的状态。
 - **撤销进程法**。强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。
 - **进程回退法**。让一（多）个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。

### 2.3.6 死锁检测与死锁恢复
**死锁检测算法**
死锁检测的基本思想是，如果一个进程所请求的资源能够被满足，那么就让它执行，否则释放它拥有的所有资源，然后让其它能满足条件的进程执行。


## 三.内存管理
### 3.1 分页存储管理
#### 3.1.1 基本思想
将程序的逻辑地址空间划分为固定大小的**页(page)**，而物理内存划分为同样大小的**页框(page frame)或物理块**，每个物理块的大小一般取2的整数幂。程序加载时，可将任意一页放人内存中任意一个页框，这些页框不必连续，从而实现了离散分配。

该方法需要CPU的硬件支持，来实现逻辑地址和物理地址之间的映射。在页式存储管理方式中地址结构由两部构成，前一部分是页号，后一部分为页内地址w（位移量）。

逻辑地址道物理地址变化原理：CPU中的内存管理单元(MMU)按逻辑页号通过查进程页表得到物理页框号，将物理页框号与页内地址相加形成物理地址。
#### 3.1.2 页式管理方式的优点
- 没有外碎片，每个内碎片不超过页大比前面所讨论的几种管理方式的最大进步是。提高内存的利用率。
- 一个程序不必连续存放。
- 便于改变程序占用空间的大小(主要指随着程序运行，动态生成的数据增多，所要求的地址空间相应增长)。

#### 3.1.3 缺点
1. 无论数据有多少，都只能按照页面大小分配，容易产生**内部碎片**（一个页可能填充不满，造成浪费。
2. 不能体现程序逻辑, 不利于编程时的独立性，并给换入换出处理、存储保护和存储共享等操作造成麻烦。
3. 分页方式的缺点是页长与程序的逻辑大小不相关

### 3.2 分段存储
#### 3.2.1 思想
将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，也实现了离散分配。通常，程序员把子程序、操作数和常数等不同类型的数据划分到不同的段中（写c程序时会用到），并且每个程序可以有多个相同类型的段。段表本身也是一个段，可以存在辅存中，但一般是驻留在主存中。

在段式虚拟存储系统中，虚拟地址由**段号和段内地址**组成，虚拟地址到实存地址的变换通过段表来实现。

在为某个段分配物理内存时，可以采用**首先适配法、下次适配法、最佳适配法等**方法。在回收某个段所占用的空间时，要注意将收回的空间与其相邻的空间合并。

#### 3.2.2 地址映射
在段式 管理系统中，整个进程的地址空间是**二维**的，即其逻辑地址由段号和段内地址两部分组成。为了完成进程逻辑地址到物理地址的映射，处理器会查找内存中的段表，由段号得到段的首地址，加上段内地址，得到实际的物理地址。这个过程也是由处理器的硬件直接完成的，操作系统只需在进程切换时，将进程段表的首地址装入处理器的特定寄存器当中。这个寄存器一般被称作段表地址寄存器。     

#### 3.2.3 分段存储方式的优缺点
分页对程序员而言是不可见的，而分段通常对程序员而言是可见的，因而分段为组织程序和数据提供了方便。与页式虚拟存储器相比，段式虚拟存储器有许多优点：

 - 段的逻辑独立性使其易于**编译、管理、修改和保护**，也便于多道程序共享。
 - 段长可以根据需要动态改变，允许自由调度，以便有效利用主存空间。


因为段的长度不固定，段式虚拟存储器也有一些缺点：
 
 - 主存空间分配比较麻烦。
 - 容易在段间留下许多碎片（外部碎片），造成存储空间利用率降低。
 - 由于段长不一定是2的整数次幂，因而不能简单地像分页方式那样用虚拟地址和实存地址的最低若干二进制位作为段内地址，并与段号进行直接拼接，必须用加法操作通过段起址与段内地址的求和运算得到物理地址。因此，**段式存储管理比页式存储管理方式需要更多的硬件支持**。

### 3.3 分页和分段的主要区别
 - 页是信息的**物理单位**，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率；段则是信息的**逻辑单位**，它含有一组其意义相对完整的信息，分段的目的是为了能更好地满足用户的需要。

 - 页的**大小固定且由系统决定**，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；而**段的长度却不固定**，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。

 - **分页的作业地址空间是一维的，即单一的线性地址空间**，程序员只需利用一个记忆符，即可表示一个地址；而分段的作业地址空间则是二维的，程序员在标识一个地址是，即需给出段名，又需给出段内地址。

 - 分页信息很难保护和共享、分段存储按逻辑存储所以容易实现对段的保存和共享。

### 3.4 段页存储
程序员按照分段系统的地址结构将地址分为段号与段内位移量，地址变换机构**将段内位移量分解为页号和页内位移量**。

为实现段页式存储管理，系统应为每个进程设置一个段表，包括每段的段号，该段的页表始址和页表长度。每个段有自己的页表，记录段中的每一页的页号和存放在主存中的物理块.

**它首先将程序按其逻辑结构划分为若干个大小不等的逻辑段，然后再将每个逻辑段划分为若干个大小相等的逻辑页**。主存空间也划分为若干个同样大小的物理页。辅存和主存之间的信息调度以页为基本传送单位，每个程序段对应一个段表，每页对应一个页表。

段页式系统中，作业的**地址结构包含三部分的内容：段号，页号，页内位移量**. CPU访问时，段表指示每段对应的页表地址，每一段的页表确定页所在的主存空间的位置，最后与页表内地址拼接，确定CPU要访问单元的物理地址。

**段页存储管理方式综合了段式管理和页式管理的优点，但需要经过两级查表才能完成地址转换，消耗时间多**。

#### 3.4.1 地址变换的过程：
 - 进行地址变换时，首先利用段号S，将它与段表长TL进行比较。若S<TL，表示未越界。
 - 利用段表始址和段号来求出该段所对应的段表项在段表中的位置，从中得到该段的页表始址
 - 利用逻辑地址中的段内页号P来获得对应页的页表项位置，从中读出该页所在的物理块号b
 - 再利用块号b和页内地址来构成物理地址。

#### 3.4.2 段页式存储管理的优缺点
优点:

 - 它提供了更大的的虚拟存储空间。
 - 能有效地利用主存，为组织多道程序运行提供了方便。
 
缺点：

- 增加了硬件成本、系统的复杂性和管理上的开消。
- 存在着系统发生抖动的危险。
- 存在着内碎片。
- 还有各种表格要占用主存空间。

段页式存储管理技术对当前的大、中型计算机系统来说，算是最通用、最灵活的一种方案。

### 3.5 虚拟内存。
**物理内存**:在应用中，自然是顾名思义，物理上，真实的插在板子上的内存是多大就是多大了。而在CPU中的概念，物理内存就是CPU的地址线可以直接进行寻址的内存空间大小。

**虚拟内存**:它使得应用程序认为它拥有连续的可用的内存(一个连续完整的地址空间),而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

### 3.6. 虚拟地址、逻辑地址、线性地址、物理地址的区别。 
**虚拟地址**：指的是由程序产生的由段选择符和段内偏移地址两个部分组成的地址。为什么叫它是虚拟的地址呢？因为这两部分组成的地址并没有直接访问物理内存，而是要通过分段地址的变换机构处理或映射后才会对应到相应的物理内存地址。

**逻辑地址**：指由程序产生的与段相关的偏移地址部分。不过有些资料是直接把逻辑地址当成虚拟地址，两者并没有明确的界限。

**线性地址**：指的是虚拟地址到物理地址变换之间的中间层，是处理器可寻指的内存空间（称为线性地址空间）中的地址。程序代码会产生逻辑地址，或者说是段中的偏移地址，加上相应段的基地址就生成了一个线性地址。如果启用了分页机制，那么线性地址可以再经过变换产生物理地址。若是没有采用分页机制，那么线性地址就是物理地址。

**物理地址**：指的是现在CPU外部地址总线上的寻址物理内存的地址信号，是地址变换的最终结果！

### 3.7 分页调度算法
#### 1. 先进先出算法(FIFO)
所选择换出的页面是最先进入的页面。该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

#### 2. 最优置换算法
所选择的老页应是将来不再被使用，或者是在**最远的将来才被访问**。采用这种页面置换算法，保证有最少的缺页率。 但是最优页面置换算法的实现是困难的.

#### 3. LRU（最近最少使用）算法 
最近最久未使用的页面换出。可以用栈来实现该算法.

#### 4.时钟算法
 首先，将内存中的所有页面链接成一个循环队列，当缺页中断发生时，检查当前指针所指向页面的访问位，如果访问位为 0，就将该页面换出；否则将该页的访问位设置为 0，给该页面第二次的机会，移动指针继续检查。


## 五. 磁盘调度算法
### 先来先服务（FCFS, First Come First Service）
其根据进程请求访问磁盘的先后顺序进行调度，优点是公平、简单，每个进程的请求都能得到依次处理，不会出现某个进程的请求长期得不到满足的情况。

### 最短寻道时间优先（SSTF，Shortest Seek Time First）
要求访问的磁道与当前磁头所在的磁道距离最近，以使每次的寻道时间最短。但这种算法不能保证平均寻道时间最短。

###  扫描（SCAN）算法
也就是很形象的电梯调度算法，先按照一个方向(比如从外向内扫描)，扫描的过程中依次访问要求服务的序列。当扫描到最里层的一个服务序列时**反向扫描**。 和电梯一样到顶层和底层的时候就反向移动了, 该算法是**双向移动**的。

### 循环扫描（CSCAN）算法
CSCAN算法始终**保持一个方向移动**，将一个最后一个磁道和第一个磁道连接，构成一个循环，按一个方向不断轮询。



