# 
我们不仅要学会面对成功，而且要学会面对失败和困难，这样才能进步。
学习方法：

 - 多看：
   - 看别人的代码是如何解决问题
   - 看身边同事如何解决问题

 - 多练
   - 在练习的基础上采用理性的思考

 - 多思考、多练习
   - 思考技术的缺点
   - 我们用它可以解决什么核心问题
   - 相关技术有哪些、它们有什么区别
   - 为什么这么设计，有没有更好的设计
 - 多总结
   - 周总结、月总结、季度总结、年总结。
   - 总结感悟、遇到的问题、思考
   - 思考如何做的更好
   - 当你学到问题的本质、看到了以前看不到的东西时、应该总结这些东西。长期坚持积累是厚积薄发的基础。

# 二. java程序员要知道的计算机工作原理
CPU在执行任务时，首先将内存中的数据读入，进行处理，处理完成后再将结果写会到内存区域。因为CPU是高速设备，内存读取效率相对降低，为了减少CPU与内存之间的速度不匹配问题，在CPU处理器中引入了多级缓存(一级缓存、二级缓存、三级缓存)。通过缓存加快数据读入和写出效率。

但是在多核CPU中，每个机器都有自己的缓存设置，导致内存数据和缓存数据不一致。 为了保证数据的一致性。 CPU引入了**缓存一致性协议**


**cache line（缓存行）**：是缓存中的内存单元，它将连续的一段内存区域进行缓存，通常采用64字节作为基本单位进行cache操作。这里考虑了double是64字节，不应该拆分为多个。



**javap**: 可以看java编译后的字节码对应的执行指令
![](media/15255756153365.jpg)


   
  
      
## CPU缓存
### 为什么有缓存
随着工艺的提升最近几十年CPU的频率不断提升，而受制于制造工艺和成本限制，目前计算机的内存主要是DRAM并且在访问速度上没有质的突破。因此，CPU的处理速度和内存的访问速度差距越来越大，甚至可以达到上万倍。这种情况下传统的CPU通过FSB直连内存的方式显然就会因为内存访问的等待，导致计算资源大量闲置，降低CPU整体吞吐量。同时又由于内存数据访问的热点集中性，在CPU和内存之间用较为快速而成本较高的SDRAM做一层缓存，就显得性价比极高了。**在cpu中引入缓存主要是解决cpu和内存速度不匹配问题，提高cpu处理速度。**

### 为什么要有多级CPU Cache
热点数据的体积越来越大，单纯的增加一级缓存大小的性价比已经很低了。因此，就慢慢出现了在一级缓存(L1 Cache)和内存之间又增加一层访问速度和成本都介于两者之间的二级缓存(L2 Cache)。
<img src="media/15255775402722.jpg" width="400px">

### 什么是Cache Line
<img src="media/15255774232307.jpg" width="400px">



参考：

 - [关于CPU Cache -- 程序猿需要知道的那些事](http://cenalulu.github.io/linux/all-about-cpu-cache/)
 - [从缓存行出发理解volatile变量、伪共享False sharing、disruptor](https://blog.csdn.net/opensure/article/details/46669337)


